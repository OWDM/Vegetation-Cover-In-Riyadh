{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for NDVI, SAVI, SDMI, Temperature, and Precipitation data\n",
    "ndvi_folder = \"C:\\\\Users\\\\Musae\\\\Documents\\\\GitHub-REPOs\\\\Senior-project_Doc\\\\Docs\\\\Array\\\\NDVI-Array\"\n",
    "savi_folder = \"C:\\\\Users\\\\Musae\\\\Documents\\\\GitHub-REPOs\\\\Senior-project_Doc\\\\Docs\\\\Array\\\\SAVI-Array\"\n",
    "sdmi_folder = \"C:\\\\Users\\\\Musae\\\\Documents\\\\GitHub-REPOs\\\\Senior-project_Doc\\\\Docs\\\\Array\\\\NDMI-Array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract patches from an image using a generator to save memory\n",
    "def extract_patches_generator(image, patch_size=(128, 128), step=128):\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    patch_height, patch_width = patch_size\n",
    "    \n",
    "    for y in range(0, img_height, step):\n",
    "        for x in range(0, img_width, step):\n",
    "            patch = image[y:y+patch_height, x:x+patch_width]\n",
    "            if patch.shape[0] == patch_height and patch.shape[1] == patch_width:\n",
    "                yield patch.astype(np.float32)  # Convert patch to float32 to save memory\n",
    "\n",
    "# Function to load an image or .npy file\n",
    "def load_image(file_path):\n",
    "    if file_path.endswith('.npy'):\n",
    "        return np.load(file_path).astype(np.float32)  # Convert to float32 to save memory\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format: {}\".format(file_path))\n",
    "\n",
    "# Function to process a folder of .npy files, yielding patches from each file to save memory\n",
    "def process_folder_generator(folder_path, patch_size=(128, 128), step=128):\n",
    "    file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        image = load_image(file_path)\n",
    "        for patch in extract_patches_generator(image, patch_size=patch_size, step=step):\n",
    "            yield patch\n",
    "\n",
    "# CSV data processing for temperature and precipitation (assuming already loaded into temperature_images and precipitation_images)\n",
    "def climate_data_generator(climate_images, patch_size=(128, 128), step=128):\n",
    "    for img in climate_images:\n",
    "        for patch in extract_patches_generator(img, patch_size=patch_size, step=step):\n",
    "            yield patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your CSV data processing for temperature and precipitation\n",
    "csv_data = pd.read_csv(\"C:\\\\Users\\\\Musae\\\\Documents\\\\GitHub-REPOs\\\\Senior-project_Doc\\\\monthly_averages_formatted.csv\")\n",
    "image_height = 6345\n",
    "image_width = 6445\n",
    "temperature_images = []\n",
    "precipitation_images = []\n",
    "\n",
    "for index, row in csv_data.iterrows():\n",
    "    temp_image = np.full((image_height, image_width), row['Temp Average'])\n",
    "    precip_image = np.full((image_height, image_width), row['PRECTOTCORR Average'])\n",
    "    temperature_images.append(temp_image)\n",
    "    precipitation_images.append(precip_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of generators\n",
    "ndvi_patches_generator = process_folder_generator(ndvi_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savi_patches_generator = process_folder_generator(savi_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdmi_patches_generator = process_folder_generator(sdmi_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_patches_generator = climate_data_generator(temperature_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_patches_generator = climate_data_generator(precipitation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_generator(*generators, batch_size=32):\n",
    "    while True:\n",
    "        batch = [next(gen) for gen in generators]  # Get next patch from each generator\n",
    "        # Correctly stack patches to form a multi-channel input\n",
    "        X_batch = np.stack(batch[:-1], axis=-1)  # Exclude label generator if used separately\n",
    "        # Reshape to ensure batch dimension is included\n",
    "        X_batch = np.reshape(X_batch, (batch_size, X_batch.shape[1], X_batch.shape[2], X_batch.shape[3]))\n",
    "        y_batch = np.array(batch[-1])  # Assuming the last generator yields labels, adjust accordingly\n",
    "        y_batch = y_batch[:batch_size]  # Ensure y_batch matches batch_size\n",
    "        yield X_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 4)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Decoder starts here\n",
    "    Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2D(1, (1, 1), activation='sigmoid', padding='same')  # Single output channel\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the loss function and metrics based on your specific task\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Use 'mean_squared_error' for regression tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_generator(*generators, batch_size=32):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        for _ in range(batch_size):  # Collect batches\n",
    "            batch = [next(gen) for gen in generators]\n",
    "            X = np.stack(batch[:-1], axis=-1)  # Stack input patches\n",
    "            y = np.expand_dims(batch[-1], axis=-1)  # Expand dims of the last generator's output for labels\n",
    "            batch_X.append(X)\n",
    "            batch_y.append(y)\n",
    "        \n",
    "        # Stack along new axis to maintain batch dimension\n",
    "        batch_X = np.stack(batch_X, axis=0)\n",
    "        batch_y = np.stack(batch_y, axis=0)\n",
    "        \n",
    "        yield batch_X, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the combined_generator\n",
    "test_combined_gen = combined_generator(ndvi_patches_generator, savi_patches_generator, sdmi_patches_generator, temperature_patches_generator, precipitation_patches_generator, batch_size=2)\n",
    "X_batch_test, y_batch_test = next(test_combined_gen)\n",
    "print(f\"X_batch shape: {X_batch_test.shape}\")\n",
    "print(f\"y_batch shape: {y_batch_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the adjusted combined_generator for model training\n",
    "# combined_gen = combined_generator(ndvi_patches_generator, savi_patches_generator, sdmi_patches_generator, temperature_patches_generator, precipitation_patches_generator, batch_size=32)\n",
    "# model.fit(combined_gen, steps_per_epoch=100, epochs=10)\n",
    "\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "\n",
    "# Compile the model with the specified optimizer\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])  # Adjust loss and metrics as needed\n",
    "\n",
    "# Use the adjusted combined_generator for model training\n",
    "combined_gen = combined_generator(ndvi_patches_generator, savi_patches_generator, sdmi_patches_generator, temperature_patches_generator, precipitation_patches_generator, batch_size=32)\n",
    "\n",
    "# Train the model with the adjusted learning rate\n",
    "history = model.fit(combined_gen, steps_per_epoch=100, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
